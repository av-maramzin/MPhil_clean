\chapter{Introduction}





\quad In the modern world parallel hardware has become ubiquitous through the entire spectrum of computing systems from low-end embedded devices to high-end supercomputers. Yet and still, most of the existing software is written in a sequential fashion: be it an old legacy software initially designed to run on the available at that time serial hardware or modern applications being developed by application domain experts rather than performance engineers. In order to exploit all available hardware facilities software has to be parallelized.\newline\null
\quad The problem of software parallelization is multifaceted and requires of programmers to possess an additional (apart from their application domain expertise) knowledge in various domains of parallel programming (from cache coherence protocols to high level algorithmic skeletons). The task of software parallelization is a challenging one. Done in the wrong way software parallelization can even slow the program down in comparison to its original sequential version. For decades researches and engineers have been working on alleviating the challenging task of software parallelization. One of these work directions is automatic parallelization techniques, which are supposed to ultimately liberate programmers from the challenging task of manual parallelization. But, despite the massive body of work on the subject, automatic techniques still cannot deliver performance levels expert programmers reach and are limited to narrow domains of scientific Fortran codes and relatively simple computational idioms.\newline\null
\quad Given the difficulty of the obstacles faced by automatic parallelisation today, we do not expect a breakthrough in the area or a "silver bullet" solving the problem in the near future. We acknowledge the role of a human expert, but at the same time we propose an assistant solution, which can be used to guide programmer's efforts and alleviate the manual parallelisation task.\newline\null
\quad The assistant solution we propose is as multifaceted as the problem itself and consists of several components aimed to tackle different aspects of software parallelisability. It is a toolkit rather than a single tool. The first tool in the toolkit has been designed, developed and assessed during the first year of my PhD. Complementary tools are supposed to be developed over the course of remaining time.\newline\null
\quad The designed tool is basically a machine learning (ML) based model of loop parallelisability integrated and utilised into an assistant scheme. Assistant takes an application to be parallelised along with its profile as an input and presents a programmer with a ranking of application loops. In contrast to a profile guided approach, assistant's ranking highlights application loops, which are not only long-running (and thus potentially profitable), but crucially parallelisable. This way a programmer concentrates his efforts on promising application loops and converges to the best achievable performance faster. We have deployed our assistant on SNU NAS Parallel Benchmarks \cite{snu-npb-benchmarks} \cite{nasa-parallel-benchmarks} and demonstrated a potential of our idea \cite{aiseps}.\newline\null
\quad The second tool we want to add to our software parallelisation toolkit solution is aimed at addressing the problem of unsuccessful data structure choice, which might turn a perfectly parallelisable at a higher level computation into a non-parallelisable lower level implementation. The tool is at the literature review and feasibility study stage.




% parallel hardware is ubiquitous, but software is sequential

\quad Parallel hardware has become ubiquitous through the entire spectrum of computing systems, from low-end embedded devices to high-end supercomputers. Yet, most of the existing software is written in a sequential fashion. In order to exploit all available hardware facilities software has to be parallelized.

% software parallelization is a complex and multifaceted topic 

\quad The task of \textbf{software parallelization} is multifaceted and complex. A perfectly decomposable and parallelizable problem might end up being implemented with an unsuccessfully chosen non-parallelizable algorithm. And the algorithm in its turn might end up being implemented with an unsuccessfully chosen lower level constructions such as pointers, heap-allocated and pointer-linked data structures, indirect array referencing, etc. Legacy source code bases have been designed primarily for serial machines and are rich with all these sub-optimal from the angle of software parallelization programming decisions.

% a knowledge programmers should possess 

\quad To avoid making all the above implementation mistakes programmers need to possess an additional knowledge in various domains of parallel programming. It is not always realistic to expect such a deep expertise from an average programmer. Decades of research have gone into parallelizing compiler technology, but despite all the advances it still fails to tackle real world legacy code challenges. Software parallelization remains a largely manual task where the key resource is expert time.

% automatic parallelization obstacles 

\quad Given the obstacles automatic parallelization faces today, we do not expect a breakthrough in the area or a "silver bullet" solving the problem in the near future. We acknowledge the role of a human expert, but at the same time we propose an \textbf{assistant solution}, which can be used to guide programmer's efforts and alleviate the manual parallelization task.

% assistant solution

\quad The assistant solution we propose is as multifaceted as the problem itself. To fully exploit all the potential of software parallelization a programmer has to work on several conceptual levels. 

% computational frameworks library

\quad The programmer starts on the high level of problem domain and algorithm. The task is to find independent parts in the problem to be solved in parallel. If there are dependencies among them, then the programmer has to design a synchronization mechanism. In our solution package we propose an off-the-shelf C++ template library of computational frameworks. The latter are ready to use parallelism patterns. A programmer only needs to customize his computation through an LLVM-like interface.

% software parallelization assistant

\quad Another tool from our solution package work on the lower final implementation level and aims at finer-grained parallelism, specifically program loops. The designed tool is basically a machine learning (ML) based model of loop parallelisability integrated and utilised into an assistant scheme. Assistant takes an application to be parallelised along with its profile as an input and presents a programmer with a ranking of application loops. In contrast to a profile guided approach, assistant's ranking highlights application loops, which are not only long-running (and thus potentially profitable), but crucially parallelisable. This way a programmer concentrates his efforts on promising application loops and converges to the best achievable performance faster. We have deployed our assistant on SNU NAS Parallel Benchmarks \cite{snu-npb-benchmarks} \cite{nasa-parallel-benchmarks} and demonstrated a potential of our idea \cite{aiseps}.



\section{Proposed Solution}
\quad With all the problems described in the section [], we make a yet another step towards alleviating the challenging task of software parallelization. In our work we propose some ideas that might be elaborated further on. We prototype our ideas on the real benchmarks and show their potential. The first idea is that of a software parallelization assistant. The second ideas proposes a notion of computational frameworks. We ship the C++ library with the prototype implementation. The frameworks have been used to rewrite the old legacy C Olden benchmarks to a higher abstraction levels and achieve some parallel speedups.

\subsection{Software Parallelization Assistant}
\quad Despite decades of research into parallelizing compiler technology, software parallelization remains a largely manual task where the key resource is expert time. In this paper we focus on the time-consuming task of identifying those loops in a program, which are both worthwhile and feasible to parallelize. We present a methodology and tool which make better use of expert time by guiding their effort directly towards those loops, where the largest performance gains can be expected while keeping analysis and transformation effort at a minimum.
  
We have developed a novel parallelization assistant that provides programmers with a ranking of all loops in a program based on their overall merit. For each loop this metric combines its potential contribution to speedup and an estimated probability for its successful parallelization. This probability is predicted using a machine learning model, which has been trained, validated, and tested on 1415 labelled loops, achieving a prediction accuracy greater than 90\%.
  
We have evaluated our parallelization assistant against sequential C applications from the SNU NAS benchmark suite. We show that our novel methodology achieves parallel performance levels comparable to those from expert programmers while requiring less expert time. On average, our assistant reduces the number of lines of code that have to be inspected manually before reaching expert-level parallel speedup by 20\%. %On average, our assistant reduces the number of loops to inspect manually by 20\% before reaching expert-level parallel speedup.

\subsection{Computational Frameworks}
\quad In this work we propose an idea of computational frameworks. As algorithms and data structures are often inseparable we blend the two into the notion of a computational framework.  