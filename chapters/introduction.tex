\chapter{Introduction}
\label{introduction}

\section{Overview}
\label{introduction_overview}
% The importance of software parallelization
\quad Parallelism has become pervasive in the world of computing, with parallel hardware omnipresent across the whole spectrum of various computing systems from low-end embedded processors to high-end supercomputers. Yet, most of the existing software is written in a sequential fashion: be it an old legacy software initially designed to run on the available at that time serial hardware or modern applications being developed by application domain experts rather than performance engineers. In order to exploit all available hardware facilities software has to be parallelized.
\begin{center}
\textbf{\large \textit{The software parallelization problem}}
\end{center}
% Challenges in the field
\begin{description}[style=unboxed,leftmargin=0cm]
\itemsep0em
\item[\textit{Manual parallelization challenges}] The task of software parallelization has characteristically been a very manual process, which is multifaceted, extremely complex, time consuming and error-prone. An embarrassingly parallel problem might end up being hidden behind a thoughtless software design, a serial algorithm or being implemented with an unsuccessfully chosen lover level constructs, such as pointers, heap-allocated and pointer-linked data structures, indirect array referencing, etc. To elegantly and effectively map a parallel problem onto the exact hardware a programmer must work on the various abstract levels and possess an expert-level knowledge in the range of various fields from software design and algorithmic patterns in software engineering down to compiler's automatic vectorization and hardware cache coherence protocols. It is not always realistic to expect such a deep expertise from an average programmer. Done in the wrong way software parallelization can even slow the program down in comparison to its original sequential version. 
\item[\textit{Automatic parallelization limitations}] Given the difficulty of the manual software parallelization, there have been numerous efforts aimed at automating the task \cite{Bacon:1994:CTH:197405.197406}, but despite decades of intensive research into the area \cite{6813266}, fully exploiting the potential of modern multi- and many-core hardware still requires a significant manual effort. Furthermore, the automatic parallelization techniques are limited to narrow domains of scientific Fortran codes and relatively simple computational idioms. Thrown at the wrong domain, these methods can even lead to program performance degradation. 
\item[\textit{ML based parallelization applicability}] There were attempts to tackle the problem from another side. There is a vast body of research into utilizing more exotic to the field of software parallelization machine learning based methods. A good overview is provided by \cite{ml-oboyle}. Although these methods have proved to be extremely useful and high performing on some compilation technology problems like selecting the best compiler flags or finding the most optimal compiler optimization parameters (like loop unroll or function inline factors). Due to the inherent statistical errors and unavailability of large training data sets these methods have not yet found a widespread application in the area of software parallelization.
\end{description}
\begin{center}
\textbf{\large \textit{The assistant solution}}
\end{center}
\quad In our project we are not trying to find a "silver bullet" and solve the problem of automatic parallelization. Neither do we try to tune machine learning algorithms to a perfect 100\% prediction accuracy. Given the difficulty of the obstacles faced by the field today, we do not expect that programmers will be liberated from performing manual parallelization in the near future~\cite{Larsen:2012:PML:2410141.2410600}. Instead, we acknowledge the role of a human programmer in the software parallelization process, but we do not expect the programmer to be an expert either. All we try to do is to \textit{\textbf{reduce the manual effort}} by providing a programmer with a parallelization \textit{assistant solution}. Our solution alleviates the task and makes it more accessible for an average programmer. The assistant solution we propose is as multifaceted as the problem itself. To fully exploit all the potential of software parallelization a programmer has to work on several conceptual levels. Thus, the assistant solution consists of a machine learning based loop parallelization tool \cite{aiseps} aiming at the finest levels of granularity and a library of computational frameworks \cite{library-repo} aiming at a coarse grained paralleliation on a high level of software architecture design, algorithm and data structure choice.

\section{Loop parallelization assistant}
\label{introduction_assistant}
\quad Despite decades of intensive research in automatic software
parallelization~\cite{6813266}, fully exploiting the potential of modern multi- and many-core hardware still requires a significant manual effort. Chapter \ref{assistant} introduces a novel parallelization assistant tool that aids a programmer in the process of parallelizing a program in the frequent case where automatic approaches fail to do so. The assistant works at the finer levels of granularity, namely the program loops. Loops are compelling candidates for parallelization, as they are naturally decomposable and tend to capture most of the execution time in a program. The assistant reduces the manual effort in this process by presenting a programmer with a ranking of program loops that are most likely to 1) require little or no effort for successful parallelization and 2) improve the program's performance when parallelized. Thus, it improves over the traditional, profile-guided process by also taking into account the \emph{probability} of potential parallelization for each of the profiled loops.

At the core of our parallelization assistant resides a novel machine-learning (ML) model of loop parallelizability. Focusing on loops allows the model to leverage a large amount of specific analyses available in modern compilers, such as generalized iterator recognition~\cite{Manilov:2018:GPI:3178372.3179511} and loop dependence analysis~\cite{Jensen:2017:ILD:3132652.3095754}. The model encodes the results of these analyses together with basic properties of the loops as machine learning \textit{features}. The loop parallelizability model is trained, validated, and tested on 1415 loops from the SNU NAS Parallel Benchmarks (SNU NPB)~\cite{Seo:2011:PCN:2357490.2358063}. The loops are labelled using a combination of expert OpenMP~\cite{Dagum:1998:OIA:615255.615542} annotations and optimization reports from the Intel \cpp{} Compiler (ICC), a
production-quality parallelizing compiler. The model is evaluated on multiple machine learning algorithms. The evaluation shows that -- despite the limited size of the data set -- our model achieves a prediction accuracy higher than 90\%.\newline\null
\quad The parallelization assistant combines inference on the parallelizability model with traditional profiling to rank higher those loops with a high probability of being parallelizable and impacting the program performance. An evaluation on eight programs from the SNU NPB suite shows that the program performance tends to improve faster as loops are parallelized in the ranking order suggested by our parallelization assistant compared to a traditional order based on profiling only. On average, following the order suggested by the assistant reduces by approximately 20\% the number of lines of code a programmer has to examine manually to parallelize SNU NPB to its expert-level speedup. Given the high level of effort involved in manual analysis, such a reduction can translate into substantial development cost savings.

\subsection{Contributions}
\quad In summary, the project of our machine learning based loop parallelization assistant makes the following contributions:
\begin{itemize}[style=unboxed,leftmargin=0cm]
\itemsep0em
\renewcommand\labelitemi{$\vartriangleright$}
\renewcommand\labelitemii{$\bullet$}
\item We introduce a machine learning model, which can be used to predict the probability with which sequential C loops can be parallelized (Sections~\ref{predicting_parallel_loops} and~\ref{ml_predictive_performance});
\item We integrate profiling of execution time with our novel ML model into a parallelization assistant, which guides the user through a ranked list of loops for parallelization (Section~\ref{practical_applications}); and
\item We demonstrate that our tool and methodology increase programmer productivity by identifying parallel loop candidates better than existing state-of-the-art approaches (Section~\ref{evaluation}).
\end{itemize}

\section{Computational frameworks library}
\label{introduction_frameworks}
\quad As we have already stated the problem of software parallelization is multifaceted. In order to arrive at the final solution a programmer has to work on multiple conceptual levels starting from problem decomposition and algorithm choice down to software architecture design, data structure choice and finer grained low level loop optimizations. Our solution reduces the programmer's efforts along this curved and iterative path. If our loop parallelization assistant aims at reducing programmer's efforts at the finest granularity level, the library of computational frameworks alleviates the tasks of software architecture design, as well as algorithm and data structure choice. The central motivating ground for the concept of computational frameworks and the prototype library we propose is formed by the data-centric parallelization (DCP) problem, limitations of the background work tackling the problem and the properties of the real world legacy code.
\begin{center}
\textbf{\large \textit{The data-centric parallelization problem}}
\end{center}
\begin{description}[style=unboxed,leftmargin=0cm]
\itemsep0em
\item[\textit{Data-centric parallelization (DCP) problem}] Among all lower level implementation questions, the problem of successful data structure choice stands particularly prominent and important. Listings \ref{lst:introduction_array} and \ref{lst:introduction_list} illustrate how easily the parallelization can be hampered.\newline\null
\begin{minipage}[t]{0.45\linewidth}
\begin{lstlisting}[caption={Parallelisable loop operating on a \textbf{linear array}.},label={lst:introduction_array},language=C]
for (int i=0; i<n; it++) {
  a[i]=a[i]+1;
}
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.5\linewidth}
\begin{lstlisting}[caption={Non-parallelisable loop operating on a \textbf{linked-list}.},label={lst:introduction_list},language=C]
for (p=list; p!=NULL; p=p->next) {
  p->value+=1;
}
\end{lstlisting}
\end{minipage}

If a programmer had a tool, that could automatically recognize the type and properties of data structures and even automatically substitute them with a simpler, parallelizable and more suitable alternative data structure, it would make the parallelization process a lot easier. Unfortunately, as our state of the art overview discovered, the solution to the problem is not available yet. There are a lot of various techniques and methodologies, but they all have their limitations and problems.
\item[\textit{Limitations of "The state of the art" work}] The idea of discovery of higher level entities in programs is definitely not a novel one. There are various \textit{static} and \textit{dynamic} techniques. \textit{Shape analysis} is one of the most well-known static techniques, which aims at understanding of various heap-allocated data structures and their properties (node reachability, cyclicity, disjointedness, etc.) at compile time \cite{Sagiv:1999:PSA:292540.292552},\cite{Wilhelm:2000:SA:647476.760384}, \cite{Ghiya:1996:TDC:237721.237724}). \textit{Shape analysis techniques give a rough and conservative approximation (a \textit{Tree} (be it a binary tree or a linked-list), work with high error rates (\textit{DAGs} vs. \textit{Cycles}) and are provably undecidable.} One of the more recent static techniques is based on the pattern matching on the code intermediate representation (IR) level and aims at recognition of various computational idioms (such as reductions, stencils, sparse and dense linear algebra computations, etc.) \cite{Ginsbach:2018:CDS:3178372.3179515},\cite{Ginsbach:2017:DEG:3049832.3049862}, \cite{Ginsbach:2018:AML:3296957.3173182},\cite{Ginsbach:2018:AML:3296957.3173182}. \textit{The technique allows for a rapid prototyping of new compiler optimisations based on pattern recognition and its substitution with an optimised versions of matched idioms, but it is limited for a relatively simple computational idioms and entities.} 
\quad Static methods are limited in their program view to a single compilation unit. The grand challenge of data structure recognition requires a much broader view. Dynamic techniques come the closest to the solution of the DCP problem. There are numerous works available \cite{Rupprecht:2017:DID:3155562.3155607}\cite{Haller:2016:SDS:2938006.2938029}, \cite{Haller:2016:SDS:2938006.2938029}, \cite{Rupprecht:2017:DID:3155562.3155607}. These techniques are based on program instrumentation and construction of various dynamic memory allocation graphs. The idea is that these graphs along with their update operations can reflect the actual shape of the data structure. Probably, the most promising and the best performing of all is the work of a Data-structure Detection Tool (DDT) \cite{1669122}. The DDT tool can successfully recognise data structures in most of the standard libraries, such as STL, Apache (STDCXX), Borland (STLport), GLib, Trimaran achieving almost perfect recognition accuracy. Moreover, the technique has been able to recognise linked lists in Em3d and Bh Olden benchmarks. But it is still far from solving the grand problem for an arbitrary code. 
\item[\textit{Data structure and algorithm inseparability}] The motivating example is obviously far below the complexity level of the real world code. The work with data structure can be spread all around the code base: allocation and initialization happen in one translation unit, update operations on the data structure are scattered between various functions in multiple other translation units. The exact way an operation works determines the properties (cyclicity, reachability, etc.) of a data structure and ultimately its type. It is crucial to understand how an algorithm actually calls data structure update operations. \textit{Thus, all that leads to the inseparability of algorithms and data structures: understanding the data structure type might require understanding of the algorithm and vise versa; and the data structure substitution might lead to algorithm transformation.} Indeed, as our feasibility studies of SPEC CPU2006 benchmark suite have shown (Section \ref{background_benchmarks_spec}) let alone automatic techniques, it might take some weeks even for an experienced human software engineer to understand what kind of data structures a benchmark uses and how to optimize it.
\item[\textit{The ever-going trend to higher abstraction levels}] For decades there has been an ongoing trend in the process of software engineering to move up in the levels of abstraction from a bare hardware to a higher level concepts closer to a human reasoning and understanding. A move from assembly languages to languages like Fortran and C, the development of object-oriented languages and a switch from an imperative to a functional prgramming paradigm. All these steps increase programmers productivity, improve program structuredness and modularity and near the process of software design closer to a human level. The trend of moving to higher abstraction levels is not only true for software engineering in general, but for parallel software engineering in particular. For example, parallel programming models and standards like POSIX, OpenMP and MPI aim at abstracting a programmer from various hardware and operating system details. Parallel algorithmic skeletons (Section \ref{background_skeletons}) frame parallelization on the algorithmic level.
\end{description}
\begin{center}
\textbf{\large \textit{A higher level solution}}
\end{center}
\quad The task of separating data structures from algorithms seems infeasible. Moreover, for some applications and benchmarks it does not seem meaningful either. For example, the suite of Olden benchmarks is much simpler, than SPEC CPU2006, but also suffers from the same inseparability problem. For many of Olden benchmarks the data structures and algorithms are blended together, but the union they form can be framed into an elegant higher level entity, that can later be parallelized in a nice and structured way.\newline\null
\quad In our project we propose the novel notion of \textit{computational frameworks}.



The latter help a programmer with a coarse-grained parallelization tasks, such as software design, algorithm and data structure choice. We provide a prototype off-the-shelf C++ template library implementing the notion. The latter are ready to use parallelism patterns. A programmer only needs to customize his computation through an LLVM-like interface. We prototyped the library on the suite of Olden benchmarks. The parallel library version is consistently outperforming the sequential version hitting 5-6x speedups on the major benchmarks.


\subsection{Contributions}
\begin{itemize}[style=unboxed,leftmargin=0cm]
\itemsep0em
\renewcommand\labelitemi{$\vartriangleright$}
\renewcommand\labelitemii{$\bullet$}
\item We propose a novel notion of \textit{computational frameworks}, which are higher level entities that embody both the data structures and the algorithms; and
\item ship a prototype C++ template library implementing the notion in a modern, convenient, parallel and an easy to use way;
\item We have turned the suite of Olden benchmarks written in the legacy C style into a modern C++ and parallel OpenMP implementation based on our computational frameworks; and
\item demonstrate the potential of the notion and the performance of the library on the suite of Olden benchmarks (Sections~\ref{frameworks_performance_study} ), achieving consistent parallel speedups of 5-6x on the major benchmarks;
\item At last, we propose an idea of alternative software parallelization approach based on the library as a future work.
\end{itemize}

%